<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Zillow’s Zestimate, and my ensemble of regressors for highly featured data prediction - James Hope</title>
<meta name="description" content="“The Zillow Prize contest competition, sponsored by Zillow, Inc. (“Sponsor”) is open to all individuals over the age of 18 at the time of entry. The competition will contain two rounds, one public and one private.. Each round will have separate datasets, submission deadlines and instructions on how to participate. The instructions on how to participate in each round are listed below. Capitalized terms used but not defined herein have the meanings assigned to them in the Zillow Prize competition Official Rules.”">


  <meta name="author" content="James Hope">
  
  <meta property="article:author" content="James Hope">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="James Hope">
<meta property="og:title" content="Zillow’s Zestimate, and my ensemble of regressors for highly featured data prediction">
<meta property="og:url" content="/kaggle/zillow-ensemble/">


  <meta property="og:description" content="“The Zillow Prize contest competition, sponsored by Zillow, Inc. (“Sponsor”) is open to all individuals over the age of 18 at the time of entry. The competition will contain two rounds, one public and one private.. Each round will have separate datasets, submission deadlines and instructions on how to participate. The instructions on how to participate in each round are listed below. Capitalized terms used but not defined herein have the meanings assigned to them in the Zillow Prize competition Official Rules.”">







  <meta property="article:published_time" content="2017-08-17T20:46:34+01:00">





  

  


<link rel="canonical" href="/kaggle/zillow-ensemble/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "James Hope",
      "url": "/",
      "sameAs": ["https://twitter.com/","https://github.com/"]
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="James Hope Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          James Hope
          
        </a>
        <ul class="visible-links"></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="/">
        <img src="/assets/images/bio-photo.jpg" alt="James Hope" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="/" itemprop="url">James Hope</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Enabling organisations and teams to realise the value of data, cloud and technology innovation through modern cloud-native architectures. IBM Garage Solution Architect. Certified Data Scientist. Views and opinions are my own.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">London</span>
        </li>
      

      
        
          
            <li><a href="https://github.com/jamesdhope" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://linkedin.com/in/jamesdometthope" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <div class="archive">
    
      <h1 id="page-title" class="page__title">Zillow's Zestimate, and my ensemble of regressors for highly featured data prediction</h1>
    
    <p>“The Zillow Prize contest competition, sponsored by Zillow, Inc. (“Sponsor”) is open to all individuals over the age of 18 at the time of entry. The competition will contain two rounds, one public and one private.. Each round will have separate datasets, submission deadlines and instructions on how to participate. The instructions on how to participate in each round are listed below. Capitalized terms used but not defined herein have the meanings assigned to them in the Zillow Prize competition Official Rules.”</p>

<p>For a full description of the competition, datasets, evaluation, prizes visit <a href="https://www.kaggle.com/c/zillow-prize-1" target="_blank">https://www.kaggle.com/c/zillow-prize-1</a></p>

<p>My first competition entry, a stacked ensemble of regressors for this competition is available here: <a href="https://www.kaggle.com/jamesdhope/zillow-ensemble-of-regressors-0-065" target="_blank">https://www.kaggle.com/jamesdhope/zillow-ensemble-of-regressors-0-065<a></a></a></p>

<p><b>Short summary</b>. The stacked ensemble makes use of the SciKit-Learn RandomForestRegressor, ExtraTreesRegressor, GradientBoostRegressor and AdaBoostRegressor, as well as a Support Vector Machine. We also make use of xgboost to perform regression over the features of the first level ensemble and is used to make final predictions on a set of circa 3 million houses, each with 23 features, for 6 points in time (that’s 12 million predictions!).</p>

<p>Whilst there is room for improvement in preprocessing, including optimising strategies for overcoming missing data (for which there is a lot!), and determining the hyperparameters that lead to an optimal model, this machine learning model is easily adapted for making predictions on featured data in any context.</p>

<p><b>Now walking through the code in some more detail…</b>. The stacked ensemble makes use of the SciKit-Learn RandomForestRegressor, ExtraTreesRegressor, GradientBoostRegressor and AdaBoostRegressor, as well as a Support Vector Machine. We also make use of xgboost to perform regression over the features of the first level ensemble. So we start out by importing the libraries we will need.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Load in our libraries
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">import</span> <span class="nn">plotly.offline</span> <span class="k">as</span> <span class="n">py</span>
<span class="n">py</span><span class="p">.</span><span class="n">init_notebook_mode</span><span class="p">(</span><span class="n">connected</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objs</span> <span class="k">as</span> <span class="n">go</span>
<span class="kn">import</span> <span class="nn">plotly.tools</span> <span class="k">as</span> <span class="n">tls</span>

<span class="c1"># Going to use these 5 base models for the stacking
</span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">AdaBoostRegressor</span><span class="p">,</span> <span class="n">ExtraTreesRegressor</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVR</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">;</span></code></pre></figure>

<p>We also need to load in the training and test datasets that Zillow has provided us.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../input/properties_2016.csv'</span><span class="p">)</span>
<span class="n">train_label</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../input/train_2016_v2.csv'</span><span class="p">)</span>
<span class="n">ParcelID</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'parcelid'</span><span class="p">]</span></code></pre></figure>

<p>Next, we will OneHotEncode some of the features. For some features, it makes sense to assume that missing data means a missing feature, so we can map Nan values to 0.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># OneHotEncoding
</span><span class="n">train</span><span class="p">[</span><span class="s">'has_basement'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">"basementsqft"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'hashottuborspa'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">"hashottuborspa"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'has_pool'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">"poolcnt"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'has_airconditioning'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">"airconditioningtypeid"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span></code></pre></figure>

<p>There are some columns which appear to need consolidating into a single feature.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Columns to be consolidated
</span><span class="n">train</span><span class="p">[</span><span class="s">'yardbuildingsqft17'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'yardbuildingsqft17'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'yardbuildingsqft26'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'yardbuildingsqft26'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'yard_building_square_feet'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'yardbuildingsqft17'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="n">train</span><span class="p">[</span><span class="s">'yardbuildingsqft26'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span></code></pre></figure>

<p>And we can also assume some more friendly feature names.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'fireplacecnt'</span><span class="p">:</span><span class="s">'fireplace_count'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'bedroomcnt'</span><span class="p">:</span><span class="s">'bedroom_count'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'bathroomcnt'</span><span class="p">:</span><span class="s">'bathroom_count'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'calculatedfinishedsquarefeet'</span><span class="p">:</span><span class="s">'square_feet'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'garagecarcnt'</span><span class="p">:</span><span class="s">'garage_car_count'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'garagetotalsqft'</span><span class="p">:</span><span class="s">'garage_square_feet'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'hashottuborspa'</span><span class="p">:</span><span class="s">'has_hottub_or_spa'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'landtaxvaluedollarcnt'</span><span class="p">:</span><span class="s">'land_tax'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'lotsizesquarefeet'</span><span class="p">:</span><span class="s">'lot_size_square_feet'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'taxvaluedollarcnt'</span><span class="p">:</span><span class="s">'tax_value'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'taxamount'</span><span class="p">:</span><span class="s">'tax_amount'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'structuretaxvaluedollarcnt'</span><span class="p">:</span><span class="s">'structure_tax_value'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'yearbuilt'</span><span class="p">:</span><span class="s">'year_built'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'roomcnt'</span><span class="p">:</span><span class="s">'room_count'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p>We also need to impute values for missing features. We can impute the median feature value across most features as a starting point.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Impute zero for NaN for these features
</span><span class="n">train</span><span class="p">[</span><span class="s">'fireplace_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'fireplace_count'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># Impute median value for NaN for these features
</span><span class="n">train</span><span class="p">[</span><span class="s">'bathroom_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'bathroom_count'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'bathroom_count'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'bedroom_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'bedroom_count'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'bedroom_count'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'room_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'room_count'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'room_count'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'tax_amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'tax_amount'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'tax_amount'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'land_tax'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'land_tax'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'land_tax'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'tax_value'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'tax_value'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'tax_value'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'structure_tax_value'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'structure_tax_value'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'structure_tax_value'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'garage_square_feet'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'garage_square_feet'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'garage_square_feet'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'garage_car_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'garage_car_count'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'garage_car_count'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'fireplace_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'fireplace_count'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'fireplace_count'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'square_feet'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'square_feet'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'square_feet'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'year_built'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'year_built'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'year_built'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'lot_size_square_feet'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'lot_size_square_feet'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'lot_size_square_feet'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'longitude'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'longitude'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'longitude'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'latitude'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'latitude'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'latitude'</span><span class="p">].</span><span class="n">median</span><span class="p">()).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span></code></pre></figure>

<p>Now on to Feature Selection. We will drop features where the volume of missing data exceeds a certain threshold. These features were not considered for imputation above.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Drop indistinct features
</span><span class="n">drop_elements</span> <span class="o">=</span> <span class="p">[</span><span class="s">'assessmentyear'</span><span class="p">]</span>
<span class="c1"># Drop any columns insufficiently described
</span><span class="n">drop_elements</span> <span class="o">=</span> <span class="n">drop_elements</span> <span class="o">+</span> <span class="p">[</span><span class="s">'airconditioningtypeid'</span><span class="p">,</span> <span class="s">'basementsqft'</span><span class="p">,</span> <span class="s">'architecturalstyletypeid'</span><span class="p">,</span> <span class="s">'buildingclasstypeid'</span><span class="p">,</span> <span class="s">'buildingqualitytypeid'</span><span class="p">,</span> <span class="s">'calculatedbathnbr'</span><span class="p">,</span> <span class="s">'decktypeid'</span><span class="p">,</span> <span class="s">'finishedfloor1squarefeet'</span><span class="p">,</span>
                 <span class="s">'fips'</span><span class="p">,</span> <span class="s">'heatingorsystemtypeid'</span><span class="p">,</span> <span class="s">'rawcensustractandblock'</span><span class="p">,</span>
                 <span class="s">'numberofstories'</span><span class="p">,</span> <span class="s">'storytypeid'</span><span class="p">,</span> <span class="s">'threequarterbathnbr'</span><span class="p">,</span> <span class="s">'typeconstructiontypeid'</span><span class="p">,</span> <span class="s">'unitcnt'</span><span class="p">,</span> <span class="s">'censustractandblock'</span><span class="p">,</span> <span class="s">'fireplaceflag'</span><span class="p">,</span> <span class="s">'taxdelinquencyflag'</span><span class="p">,</span> <span class="s">'taxdelinquencyyear'</span><span class="p">,</span>
                <span class="p">]</span>
<span class="c1"># Drop any duplicated columns
</span><span class="n">drop_elements</span> <span class="o">=</span> <span class="n">drop_elements</span> <span class="o">+</span> <span class="p">[</span><span class="s">'fullbathcnt'</span><span class="p">,</span> <span class="s">'finishedsquarefeet6'</span><span class="p">,</span> <span class="s">'finishedsquarefeet12'</span><span class="p">,</span> <span class="s">'finishedsquarefeet13'</span><span class="p">,</span> <span class="s">'finishedsquarefeet15'</span><span class="p">,</span> <span class="s">'finishedsquarefeet50'</span><span class="p">,</span> <span class="s">'yardbuildingsqft17'</span><span class="p">,</span> <span class="s">'yardbuildingsqft26'</span><span class="p">]</span>
<span class="c1"># Land use data
</span><span class="n">drop_elements</span> <span class="o">=</span> <span class="n">drop_elements</span> <span class="o">+</span> <span class="p">[</span><span class="s">'propertycountylandusecode'</span><span class="p">,</span> <span class="s">'propertylandusetypeid'</span><span class="p">,</span> <span class="s">'propertyzoningdesc'</span><span class="p">]</span>
<span class="c1"># We'll make do with a binary feature here
</span><span class="n">drop_elements</span> <span class="o">=</span> <span class="n">drop_elements</span> <span class="o">+</span> <span class="p">[</span><span class="s">'pooltypeid10'</span><span class="p">,</span> <span class="s">'pooltypeid2'</span><span class="p">,</span> <span class="s">'pooltypeid7'</span><span class="p">,</span> <span class="s">'poolsizesum'</span><span class="p">,</span> <span class="s">'poolcnt'</span><span class="p">]</span>
<span class="c1"># We'll use the longitude and latitutde as features 
</span><span class="n">drop_elements</span> <span class="o">=</span> <span class="n">drop_elements</span> <span class="o">+</span> <span class="p">[</span><span class="s">'regionidzip'</span><span class="p">,</span> <span class="s">'regionidneighborhood'</span><span class="p">,</span> <span class="s">'regionidcity'</span><span class="p">,</span> <span class="s">'regionidcounty'</span><span class="p">]</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_elements</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span></code></pre></figure>

<p>We can now correlate the features using the Seaborn library Pearson’s Correlation. This is ideal for helping with feature reduction as ideally we want as fewer features as possible for regression. We might consider removing some more features here with a high correlation.</p>

<p><img src="/assets/zillow/pearson.jpg" width="100%" /></p>

<p>It’s also a good idea to scale the data at this point. I’ve left this out for brevity but you can refer to the full code if you are unsure how to do this.</p>

<p>Now a little preparation before we build our models. We’ll create an object called SklearnHelper that will extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn classifiers. This cuts out redundancy as won’t need to write the same methods five times if we wanted to invoke five different classifiers.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Class to extend the Sklearn classifier
</span><span class="k">class</span> <span class="nc">SklearnHelper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clf</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">params</span><span class="p">[</span><span class="s">'random_state'</span><span class="p">]</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">feature_importances</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">).</span><span class="n">feature_importances_</span><span class="p">)</span></code></pre></figure>

<p>We’ll also define a function for Cross Validation. This deserves a little explanation. The function will be passed the model, the training set and the test set (for all six time periods). It will make kf=5 folds of the training data, train the model on each fold and make predictions for each time period using this model. It will then take an average of the predicted scores across the five folds for each time period.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_oof</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_201610</span><span class="p">,</span> <span class="n">x_test_201611</span><span class="p">,</span> <span class="n">x_test_201612</span><span class="p">,</span> <span class="n">x_test_201710</span><span class="p">,</span> <span class="n">x_test_201711</span><span class="p">,</span> <span class="n">x_test_201712</span><span class="p">):</span>
    <span class="n">oof_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntrain</span><span class="p">,))</span>
    
    <span class="n">oof_test_201610</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    <span class="n">oof_test_201611</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    <span class="n">oof_test_201612</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    <span class="n">oof_test_201710</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>    
    <span class="n">oof_test_201711</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    <span class="n">oof_test_201712</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    
    <span class="n">oof_test_skf_201610</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>
    <span class="n">oof_test_skf_201611</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>
    <span class="n">oof_test_skf_201612</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>
    <span class="n">oof_test_skf_201710</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>
    <span class="n">oof_test_skf_201711</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>
    <span class="n">oof_test_skf_201712</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>
    
    <span class="c1">#train_index: indicies of training set
</span>    <span class="c1">#test_index: indicies of testing set
</span>     
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
        <span class="c1">#break the dataset down into two sets, train and test
</span>        <span class="n">x_tr</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">y_tr</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">x_te</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        
        <span class="n">clf</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
        
        <span class="c1">#make a predition on the test data subset
</span>        <span class="n">oof_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_te</span><span class="p">)</span>
        
        <span class="c1">#use the model trained on the first fold to make a prediction on the entire test data 
</span>        <span class="n">oof_test_skf_201610</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201610</span><span class="p">)</span>
        <span class="n">oof_test_skf_201611</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201611</span><span class="p">)</span>
        <span class="n">oof_test_skf_201612</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201612</span><span class="p">)</span>
        <span class="n">oof_test_skf_201710</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201710</span><span class="p">)</span>
        <span class="n">oof_test_skf_201711</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201711</span><span class="p">)</span>
        <span class="n">oof_test_skf_201712</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201712</span><span class="p">)</span>
    
    <span class="c1">#take an average of all of the folds
</span>    <span class="n">oof_test_201610</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf_201610</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">oof_test_201611</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf_201611</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">oof_test_201612</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf_201612</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">oof_test_201710</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf_201710</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">oof_test_201711</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf_201711</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">oof_test_201712</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf_201712</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">oof_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test_201610</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test_201611</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test_201612</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test_201710</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test_201711</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test_201712</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></code></pre></figure>

<p>Next we’ll create a Dict data type to hold all of our model parameters.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">SEED</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># for reproducibility
</span><span class="n">NFOLDS</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># set folds for out-of-fold prediction
</span>
<span class="c1"># Put in our parameters for said classifiers
# Random Forest parameters
</span><span class="n">rf_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'n_jobs'</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="s">'n_estimators'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
     <span class="s">'warm_start'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> 
     <span class="c1">#'max_features': 0.2,
</span>    <span class="s">'max_depth'</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
    <span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s">'max_features'</span> <span class="p">:</span> <span class="s">'sqrt'</span><span class="p">,</span>
    <span class="s">'verbose'</span><span class="p">:</span> <span class="mi">0</span>
<span class="p">}</span>

<span class="c1"># Extra Trees Parameters
</span><span class="n">et_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'n_jobs'</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="s">'n_estimators'</span><span class="p">:</span><span class="mi">500</span><span class="p">,</span>
    <span class="c1">#'max_features': 0.5,
</span>    <span class="s">'max_depth'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s">'verbose'</span><span class="p">:</span> <span class="mi">0</span>
<span class="p">}</span>

<span class="c1"># AdaBoost parameters
</span><span class="n">ada_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'n_estimators'</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s">'learning_rate'</span> <span class="p">:</span> <span class="mf">0.75</span>
<span class="p">}</span>

<span class="c1"># Gradient Boosting parameters
</span><span class="n">gb_regressor_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'n_estimators'</span><span class="p">:</span><span class="mi">500</span><span class="p">,</span> 
    <span class="s">'learning_rate'</span><span class="p">:</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="s">'max_depth'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> 
    <span class="s">'random_state'</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> 
    <span class="s">'loss'</span><span class="p">:</span><span class="s">'ls'</span>
<span class="p">}</span></code></pre></figure>

<p>We’ll now create our models.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">rf</span> <span class="o">=</span> <span class="n">SklearnHelper</span><span class="p">(</span><span class="n">clf</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">rf_params</span><span class="p">)</span>
<span class="n">et</span> <span class="o">=</span> <span class="n">SklearnHelper</span><span class="p">(</span><span class="n">clf</span><span class="o">=</span><span class="n">ExtraTreesRegressor</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">et_params</span><span class="p">)</span>
<span class="n">ada</span> <span class="o">=</span> <span class="n">SklearnHelper</span><span class="p">(</span><span class="n">clf</span><span class="o">=</span><span class="n">AdaBoostRegressor</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">ada_params</span><span class="p">)</span>
<span class="n">gb_regressor</span> <span class="o">=</span> <span class="n">SklearnHelper</span><span class="p">(</span><span class="n">clf</span><span class="o">=</span><span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">gb_regressor_params</span><span class="p">)</span></code></pre></figure>

<p>And now train the models…</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">et_oof_train</span><span class="p">,</span> <span class="n">et_oof_test_201610</span><span class="p">,</span> <span class="n">et_oof_test_201611</span><span class="p">,</span> <span class="n">et_oof_test_201612</span><span class="p">,</span> <span class="n">et_oof_test_201710</span><span class="p">,</span> <span class="n">et_oof_test_201711</span><span class="p">,</span> <span class="n">et_oof_test_201712</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">et</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_201610</span><span class="p">,</span> <span class="n">x_test_201611</span><span class="p">,</span> <span class="n">x_test_201612</span><span class="p">,</span> <span class="n">x_test_201710</span><span class="p">,</span> <span class="n">x_test_201711</span><span class="p">,</span> <span class="n">x_test_201712</span><span class="p">)</span> <span class="c1"># Extra Trees
</span><span class="n">rf_oof_train</span><span class="p">,</span> <span class="n">rf_oof_test_201610</span><span class="p">,</span> <span class="n">rf_oof_test_201611</span><span class="p">,</span> <span class="n">rf_oof_test_201612</span><span class="p">,</span> <span class="n">rf_oof_test_201710</span><span class="p">,</span> <span class="n">rf_oof_test_201711</span><span class="p">,</span> <span class="n">rf_oof_test_201712</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_201610</span><span class="p">,</span> <span class="n">x_test_201611</span><span class="p">,</span> <span class="n">x_test_201612</span><span class="p">,</span> <span class="n">x_test_201710</span><span class="p">,</span> <span class="n">x_test_201711</span><span class="p">,</span> <span class="n">x_test_201712</span><span class="p">)</span> <span class="c1"># Random Forest
</span><span class="n">ada_oof_train</span><span class="p">,</span> <span class="n">ada_oof_test_201610</span><span class="p">,</span> <span class="n">ada_oof_test_201611</span><span class="p">,</span> <span class="n">ada_oof_test_201612</span><span class="p">,</span> <span class="n">ada_oof_test_201710</span><span class="p">,</span> <span class="n">ada_oof_test_201711</span><span class="p">,</span> <span class="n">ada_oof_test_201712</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_201610</span><span class="p">,</span> <span class="n">x_test_201611</span><span class="p">,</span> <span class="n">x_test_201612</span><span class="p">,</span> <span class="n">x_test_201710</span><span class="p">,</span> <span class="n">x_test_201711</span><span class="p">,</span> <span class="n">x_test_201712</span><span class="p">)</span> <span class="c1"># AdaBoost
</span><span class="n">gb_regressor_oof_train</span><span class="p">,</span> <span class="n">gb_regressor_oof_test_201610</span><span class="p">,</span> <span class="n">gb_regressor_oof_test_201611</span><span class="p">,</span> <span class="n">gb_regressor_oof_test_201612</span><span class="p">,</span> <span class="n">gb_regressor_oof_test_201710</span><span class="p">,</span> <span class="n">gb_regressor_oof_test_201711</span><span class="p">,</span> <span class="n">gb_regressor_oof_test_201712</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">gb_regressor</span><span class="p">,</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_test_201610</span><span class="p">,</span> <span class="n">x_test_201611</span><span class="p">,</span> <span class="n">x_test_201612</span><span class="p">,</span> <span class="n">x_test_201710</span><span class="p">,</span> <span class="n">x_test_201711</span><span class="p">,</span> <span class="n">x_test_201712</span><span class="p">)</span></code></pre></figure>

<p>Finally, with the models trained, we have now reached the end of the first layer of our ensemble. We can now extract the features for further analysis.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">rf_feature</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"rf_feature"</span><span class="p">,</span> <span class="n">rf_feature</span><span class="p">)</span>
<span class="n">et_feature</span> <span class="o">=</span> <span class="n">et</span><span class="p">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"et_feature"</span><span class="p">,</span> <span class="n">et_feature</span><span class="p">)</span>
<span class="n">ada_feature</span> <span class="o">=</span> <span class="n">ada</span><span class="p">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"ada_feature"</span><span class="p">,</span> <span class="n">ada_feature</span><span class="p">)</span>
<span class="n">gb_regressor_feature</span> <span class="o">=</span> <span class="n">gb_regressor</span><span class="p">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"gb_regressor_feature"</span><span class="p">,</span> <span class="n">gb_regressor_feature</span><span class="p">)</span></code></pre></figure>

<p>The 23 features we obtain for each model are as follows:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">rf_feature</span> <span class="p">[</span> <span class="mf">0.04038533</span>  <span class="mf">0.02947441</span>  <span class="mf">0.14908661</span>  <span class="mf">0.0023588</span>   <span class="mf">0.00515421</span>  <span class="mf">0.01727217</span>
  <span class="mf">0.0020252</span>   <span class="mf">0.07555324</span>  <span class="mf">0.07418552</span>  <span class="mf">0.06010003</span>  <span class="mf">0.01318217</span>  <span class="mf">0.04547284</span>
  <span class="mf">0.11738776</span>  <span class="mf">0.09638334</span>  <span class="mf">0.07514663</span>  <span class="mf">0.11330465</span>  <span class="mf">0.00048846</span>  <span class="mf">0.00700142</span>
  <span class="mf">0.00589092</span>  <span class="mf">0.00323037</span>  <span class="mf">0.</span>          <span class="mf">0.03016362</span>  <span class="mf">0.03675231</span><span class="p">]</span>
<span class="n">et_feature</span> <span class="p">[</span> <span class="mf">0.06465583</span>  <span class="mf">0.0572915</span>   <span class="mf">0.12032578</span>  <span class="mf">0.00991171</span>  <span class="mf">0.01124228</span>  <span class="mf">0.00960876</span>
  <span class="mf">0.01485536</span>  <span class="mf">0.06740794</span>  <span class="mf">0.05175181</span>  <span class="mf">0.05436677</span>  <span class="mf">0.01772004</span>  <span class="mf">0.05594463</span>
  <span class="mf">0.09801529</span>  <span class="mf">0.0533328</span>   <span class="mf">0.0450343</span>   <span class="mf">0.08253611</span>  <span class="mf">0.00201233</span>  <span class="mf">0.02357432</span>
  <span class="mf">0.03032919</span>  <span class="mf">0.00296583</span>  <span class="mf">0.</span>          <span class="mf">0.061361</span>    <span class="mf">0.06575642</span><span class="p">]</span>
<span class="n">ada_feature</span> <span class="p">[</span>  <span class="mf">8.36785346e-03</span>   <span class="mf">3.79894667e-03</span>   <span class="mf">7.05391914e-02</span>   <span class="mf">7.82563418e-05</span>
   <span class="mf">3.22502690e-07</span>   <span class="mf">1.36595920e-02</span>   <span class="mf">0.00000000e+00</span>   <span class="mf">6.15640675e-02</span>
   <span class="mf">5.32715094e-02</span>   <span class="mf">3.73193212e-02</span>   <span class="mf">1.70693107e-02</span>   <span class="mf">1.18344505e-01</span>
   <span class="mf">1.72005440e-01</span>   <span class="mf">3.48224492e-02</span>   <span class="mf">4.48032666e-02</span>   <span class="mf">3.87885107e-02</span>
   <span class="mf">0.00000000e+00</span>   <span class="mf">7.54103834e-03</span>   <span class="mf">0.00000000e+00</span>   <span class="mf">1.06703836e-02</span>
   <span class="mf">0.00000000e+00</span>   <span class="mf">1.25617605e-01</span>   <span class="mf">1.81738430e-01</span><span class="p">]</span>
<span class="n">gb_regressor_feature</span> <span class="p">[</span> <span class="mf">0.02</span>   <span class="mf">0.012</span>  <span class="mf">0.246</span>  <span class="mf">0.</span>     <span class="mf">0.016</span>  <span class="mf">0.002</span>  <span class="mf">0.004</span>  <span class="mf">0.114</span>  <span class="mf">0.068</span>  <span class="mf">0.02</span>
  <span class="mf">0.004</span>  <span class="mf">0.012</span>  <span class="mf">0.158</span>  <span class="mf">0.056</span>  <span class="mf">0.06</span>   <span class="mf">0.16</span>   <span class="mf">0.</span>     <span class="mf">0.022</span>  <span class="mf">0.</span>     <span class="mf">0.</span>     <span class="mf">0.</span>
  <span class="mf">0.026</span>  <span class="mf">0.</span>   <span class="p">]</span></code></pre></figure>

<p>Let’s have a look at how important these features are for each model.</p>

<p><img src="/assets/zillow/newplot_1.png" width="100%" />
<img src="/assets/zillow/newplot_2.png" width="100%" />
<img src="/assets/zillow/newplot_3.png" width="100%" />
<img src="/assets/zillow/newplot_4.png" width="100%" /></p>

<p>Now, across the four models, the mean feature importances.</p>

<p><img src="/assets/zillow/newplot_5.png" width="100%" /></p>

<p>We can now build a new dataframe to hold these features, and train a regression model using xgboost on these features as our second layer.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#predictions from first layer become data input for second layer
</span><span class="n">base_predictions_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span> 
    <span class="p">{</span>
    <span class="s">'RandomForest'</span><span class="p">:</span> <span class="n">rf_oof_train</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span>
    <span class="s">'ExtraTrees'</span><span class="p">:</span> <span class="n">et_oof_train</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span>
    <span class="s">'AdaBoost'</span><span class="p">:</span> <span class="n">ada_oof_train</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span>
    <span class="s">'GradientRegressor'</span><span class="p">:</span> <span class="n">gb_regressor_oof_train</span><span class="p">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="p">})</span>
<span class="c1">#predictions for all instances in the training set
</span><span class="n">base_predictions_train</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">gbm</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="c1">#learning_rate = 0.02,
</span> <span class="n">n_estimators</span><span class="o">=</span> <span class="mi">2000</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
 <span class="c1">#gamma=1,
</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>                        
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s">'reg:linear'</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span>
 <span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></figure>

<p>Now to make our final predictions…</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">predictions_201610</span> <span class="o">=</span> <span class="n">gbm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201610</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">predictions_201611</span> <span class="o">=</span> <span class="n">gbm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201611</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">predictions_201612</span> <span class="o">=</span> <span class="n">gbm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201612</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">predictions_201710</span> <span class="o">=</span> <span class="n">gbm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201710</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">predictions_201711</span> <span class="o">=</span> <span class="n">gbm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201711</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">predictions_201712</span> <span class="o">=</span> <span class="n">gbm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_201712</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">StackingSubmission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span> <span class="s">'201610'</span><span class="p">:</span> <span class="n">predictions_201610</span><span class="p">,</span> 
                                         <span class="s">'201611'</span><span class="p">:</span> <span class="n">predictions_201611</span><span class="p">,</span>
                                         <span class="s">'201612'</span><span class="p">:</span> <span class="n">predictions_201612</span><span class="p">,</span>
                                         <span class="s">'201710'</span><span class="p">:</span> <span class="n">predictions_201710</span><span class="p">,</span>
                                         <span class="s">'201711'</span><span class="p">:</span> <span class="n">predictions_201711</span><span class="p">,</span>
                                         <span class="s">'201712'</span><span class="p">:</span> <span class="n">predictions_201712</span><span class="p">,</span>
                                         <span class="s">'ParcelId'</span><span class="p">:</span> <span class="n">ParcelID</span><span class="p">,</span>
                            <span class="p">})</span>
<span class="k">print</span><span class="p">(</span><span class="n">StackingSubmission</span><span class="p">)</span></code></pre></figure>



<ul class="taxonomy__index">
     
    <li>
        <a href="#2021">
            <strong>2021</strong> <span class="taxonomy__count">1</span>
        </a>
    </li>
    
    <li>
        <a href="#2019">
            <strong>2019</strong> <span class="taxonomy__count">4</span>
        </a>
    </li>
    
    <li>
        <a href="#2018">
            <strong>2018</strong> <span class="taxonomy__count">2</span>
        </a>
    </li>
    
    <li>
        <a href="#2017">
            <strong>2017</strong> <span class="taxonomy__count">2</span>
        </a>
    </li>
    
</ul>

  
<section id="2021" class="taxonomy__section">
    <h2 class="archive__subtitle">2021</h2>
    <div class="entries-list">
         



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/kubernetes,/digital/ocean,/solution/architecture/kubernetes-digital-ocean/" rel="permalink">Top 10 Architectural Considerations for Digital Ocean Kubernetes
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
Format: 
</p>
  </article>
</div>
 
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
</section>

<section id="2019" class="taxonomy__section">
    <h2 class="archive__subtitle">2019</h2>
    <div class="entries-list">
         



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/medium,/towardsdatascience,/peopleanalytics,/graphs,/neo4j/a-new-era-for-people-analytics/" rel="permalink">A New Era for People Analytics
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">This article was published in the journal Towards Data Science. Please click here to access the article.
</p>
  </article>
</div>
  



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/medium,/towardsdatascience,/people/analytics/can-your-people-analytics-do-this/" rel="permalink">Can your People Analytics do this?
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">This article was published in the journal Towards Data Science. Please click here to access the article.
</p>
  </article>
</div>
  



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/medium,/towardsdatascience,/peopleanalytics,/graphs,/neo4j,/machinelearning,/recommendersystems,/recommender/build-a-machine-learning-recommender/" rel="permalink">Build a Machine Learning Recommender
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">This article was published in the journal Towards Data Science. Please click here to access the article.
</p>
  </article>
</div>
  



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/medium,/towardsdatascience,/peopleanalytics,/graphs,/neo4j/build-your-own-blockchain-protocol/" rel="permalink">Build your own Blockchain Protocol
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">This article was published in the journal Towards Data Science. Please click here to access the article.
</p>
  </article>
</div>
 
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
</section>

<section id="2018" class="taxonomy__section">
    <h2 class="archive__subtitle">2018</h2>
    <div class="entries-list">
         



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/edtech,/coding,/programming,/python,/computing,/computer-science/StableGroups/" rel="permalink">Implementation of the Stable Marriage Algorithm to find ‘Stable Groups’
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In my previous post, I explained my implementation of the Stable Marriage Algorithm to find stable pairs. Taking this implementation one step further, I want...</p>
  </article>
</div>
  



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/edtech,/coding,/programming,/python,/computing,/computer-science/stable-marriage/" rel="permalink">Implementation of the Stable Marriage Algorithm.
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Ever been faced with the challenge of pairing people based on their individual preferences? I can think of numerous situations in which such a task might ari...</p>
  </article>
</div>
 
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
</section>

<section id="2017" class="taxonomy__section">
    <h2 class="archive__subtitle">2017</h2>
    <div class="entries-list">
         



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/kaggle/zillow-ensemble/" rel="permalink">Zillow’s Zestimate, and my ensemble of regressors for highly featured data prediction
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“The Zillow Prize contest competition, sponsored by Zillow, Inc. (“Sponsor”) is open to all individuals over the age of 18 at the time of entry. The competit...</p>
  </article>
</div>
  



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/kaggle/time-series-forecasting/" rel="permalink">Deep Learning Recurrent Neural Net for Time Series Forecasting
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          5 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The Notebook described here supersedes my basic Recurrent Neural Net (RNN) for predicting multiple time series for the Wikipedia page forecasting competition...</p>
  </article>
</div>
 
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
</section>

  </div>
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://github.com/jamesdhope" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://linkedin.com/in/jamesdometthope" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 James Hope. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
